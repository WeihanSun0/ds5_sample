# SPAD距離センサを用いたAR用途depth Upsamplingアルゴリズム開発

----
## 1.概要
本ドキュメントは、dToFセンサDS5を用いたAR用途のデプスUpsamplingアルゴリズム開発に関するレポートである。<br>
スマートフォンの普及に伴い、高性能・多機能なイメージセンサーへの要求が増えている。SSS社がモバイル用のイメージセンサ領域で優位に立つため、様々なセンシング技術に取り組んでいる。SPADを用いたdToFセンサーもそのうちの一つであり、DSシリーズとしてモジュール化し価値探索に取り組んでいる。DS5では前身のDS4と比べ、測距モードが増え、出力のFPS（Frames Per Second）も改善されている。<br>
一方、AI技術とハードウェアの進歩により、様々なアプリケーションがスマートフォンに搭載されることになった。そのうち、AR（Augmented Reality）が一つの注目されてる応用であり、これから様々な産業での展開を期待されている。臨場感のあるARの体験には、高い解像度のデプス出力が求められ、現状のdToFの測距点の密度ではなかなか満足できない。そのため、スパースな測距データを密な信号に補完するデプスUpsampling（後では、Upsamplingと呼ぶ）という技術を用いる。

本レポートではARに対するdepthの要求精度を整理し、それを満たすための信号処理開発の経緯をまとめる。

<!---  -->

私が所属する部署では今まで自律移動台車やAFなど用途に応じて幾つかのUpsampling方法を開発してきたが、AR用途は今回が初めてある。本開発は、ARの開発先からの要求を満たし、DS5の特性に合ったUspamplingアルゴリズムが目的である。<br>

本レポートは、以下の構成となる。<br>
* 第２章: DS5、AR、Uspamplingの紹介
* 第３章: 開発目標と設計方針
* 第４章: アルゴリズムの検討と設計
* 第５章: 実装とパラメータの説明
* 第６章: 検証方法と結果
* 第７章: まとめ

## 2. 関連技術
### 2.1 DS5
#### 2.1.1 概要
DS5は、「Horizon（高解像度SPAD）、OCL付きVCSEL」と広FOVレンズにより、1Tx & 1Rx構成である。光源Txはspot光とflood光の照射モード切替により、近距離高解像度depthと中長距離低解像depthの取得が可能な測距システムになっている。DS5で使用するデバイスとスペックについては、下記の通りである。また、配置は図1にのように、DS5モジュールにグローバルシャッター画像センサー（GS）とdToFセンサー（RX）が横に並んである。
<!--- MIS? -->

表1. DS5で使用するデバイス

| デバイス | 型番 | スペック |
| --- | --- | --- |
| ToF Rx   | Horizion              | 4800MP SPAD    |
| ToF Tx   | S6893B w/ OCL         | 432ch for flood, 144ch for spot, FOV:$100{\degree}$(H) $83.6{\degree}$(V) |
| GS sensor | Deep Imapct (B/W) | 2Mpix, 120fps, FOV:$109.6{\degree}$(H) $71.9{\degree}$(V)   |
  
図1. DS5評価環境
<!--- 図が選択したやつが表示されている TODO:-->
![500](imgs/ds5-1.png)
#### 2.1.2 出力
DS5の評価環境は図1の通りである。DS5モジュールから得た元信号が中継基板を経由し、DSY-01というjetsonベースの基板で信号処理を行ってから、USBケーブルを経由しPCに送信する。現段階ではUpsamplingはPC側で行う。
PCへの出力データは以下となる（図2に出力の例を示している）。  

  * flood ポイントクラウド（floodモード有効の時）：近距離測距による$80 \times 60$点のポイントクラウド
  * spot ポイントクラウド（spotモード有効の時）：中長距離測距による$12 \times 12$点のポイントクラウド
  * intensity（intensityモード有効の時）：解像度が$320 \times 240$である白黒IR画像 (フォトンカウント値)   
  * GS画像（GS Sensorの出力）：解像度が$960 \times 540$である白黒画像
floodポイントクラウド・spotポイントクラウド・intensity画像は時分割で出力可能である。
  図2. DS5出力の例 (左から順に、GS画像、intensity画像、floodデプスマップ、spotデプスマップ。ただし、intensity, flood, spotの値により正規化を行った) 
  ![680](imgs/example.png)
  
  ### 2.2 AR
#### 2.2.1 セグメンテーションのタスク
図3に示す例のように、ARは現実世界の情報を認識し、バーチャルの情報を現実世界に重ね合わせて表示する技術である。そのため、バーチャル世界に再現する現実世界の被写体を、複雑な背景から目標物体を綺麗に取り出すためのセグメンテーションがバーチャル空間での臨場感に重要になる。画像認識ベースのセグメンテーションと比較し、デプス情報を利用するセグメンテーションは、密で綺麗なdepthさえとれれば単純な閾値処理が軽いというメリットがあるため、今回はdTOFのdepthとupsamplingを組み合わせたdepthがARに有用かの検証を行った。

図3. ARの例（左：現実世界、右：バーチャル情報での拡張）
![600](imgs/ARexample.png)

#### 2.2.2 入力デプスに対する要求
ARアプリケーションを実現させるには実用的な観点から、入力デプスの解像度とフレームレートと精度の3つの要求を満たす必要がある。

##### **フレームレート**
動画像からのセグメンテーションの場合、出力スピードが低いと遅延が発生し、ユーザーエクスペリエンスに影響を与える重要な指標の一つである。
出力スピードに対して、ARのアプリケーションでは100 FPS以上が望ましい。

##### **精度**
デプスの精度を評価する時、MAE（Mean Absolute Error）などの各ピクセルの誤差がよく使われている。ただし、セグメンテーションの場合、距離自体の正確性よりもエッジ部分の前後関係の明瞭さが最も重視される。
本開発には、AR技術開発先が利用するPrecisionとRecallの評価指標を参考にし、セグメンテーション精度に対する評価を行った。詳細は「6. 検証・評価」に記す。AR用途の綺麗なセグメンテーションのためには、PrecisionとRecallが共に95%以上になることが要求される。

### 2.3 デプスUpsampling
#### 2.3.1 概説
デプスUpsampling（Depth Completionと同じこと。以下には、Upsamplingと呼ぶ）技術は、密な信号（guide画像）を参考し、スパースなデプス入力を密にする方法であり、多くの手法（[KITTI Depth Completion Benchmark](https://paperswithcode.com/sota/depth-completion-on-kitti-depth-completion)に記載）が提案されている。手法は一般的に、DNNベースの手法とフィルタベースに大別される。DNNベースの手法では、深層学習方法を利用し、データからモジュールを訓練する。学習済みの既知物体に対して高い精度だが、計算量が大きく、汎用性などに課題がある。一方、フィルタベースの手法は、人工設計したルールでのフィルタリング処理である。精度面で課題はあるが、処理スピードは設計により比較的容易に調整可能で早くできる傾向がある。

今回は、要件の中から処理速度を重視し、処理の軽いフィルタベースの手法を選んだ。
また、精度とスピードの様々なフィルタベースの方法がある。本開発では、幾つのUpsampling方法の比較を行った上、スピードの早いFGSを使うことにした。Upsampling手法の比較について、「4. アルゴリズムの検討」に記載する。

#### 2.3.2 FGS
D. Minらが[Fast Global Smoother](https://www.researchgate.net/profile/Dongbo-Min/publication/267871655_Fast_Global_Image_Smoothing_Based_on_Weighted_Least_Squares/links/55ad977108ae98e661a4327f/Fast-Global-Image-Smoothing-Based-on-Weighted-Least-Squares.pdf?origin=publication_detail)（以下FGSという）を提案した。詳細について、論文に記載。こちらで、Upsamplingアルゴリズムに調整可能のパラメータ$\lambda$と$\sigma$を理解のため、FGSの原理を簡単に紹介する。

FGSでは、画像全体を配慮し、式(1)で定義されたGlobalエネルギー関数$J(u)$を最小化するような目標画像（$u$）が求められる。
ここで、$p$が画像上のあるピクセルであり、$q$が$p$の隣接領域のピクセルである。そして、$u_p$が目標画像の画素値、$f_p$が入力画像の画素値、$g_p$がguide画像の画素値である。$h_p$がスパース入力のマスクであり、入力ありのところが1、入力なしのところが0になる。
$$
J(u)= \sum_p \left(h_p (u_p-f_p)^2+\lambda\sum_{q\in \mathcal{N}(p)}\omega_{p,q}(g)(u_p-u_q)^2 \right)　\tag {1}
$$
また、$\omega_{p,q}(g)$がguide画像上、$q$と$p$の類似度で、式(2)で算出する。
$$
\omega_{p,q}(g) = \exp(-||g_p-g_q||/\sigma) \tag {2}
$$
式(1)の足し算の前後が分けて、前の部分が入力$f$との差、後ろが周りとの差である。$\lambda$がそのバランスを調整するパラメータである。また、$\sigma$が隣接領域との類似度を調整するパラメータである。

式(1)を最適化すると、式(3)の結果になる。
$$
u(m)=((I+\lambda A)^{-1}f)(m)\tag{3}
$$
$m$がピクセルインデックス。$I$が単位行列であり、$A$ が$\omega$で構成された$S \times S$行列（$S=$画像幅$\times$画像高さ）である.　
$$
u(m)=\frac{((I+\lambda A)^{-1}f)(m)}{((I+\lambda A)^{-1}h)(m)} \tag{4}
$$
今回のようにsparseな入力を密にする場合は、入力信号が0の領域で元信号が減衰してしまう部分を元に戻すため、入力スパースデプスマップ$f$とマスク$h$にそれぞれフィルタを掛け、その結果の商を求めることになる。

## 3. 開発方針
利用センサの特性とAR応用開発先の要求に応じ、本開発の方針を決めた。

### 3.1 性能目標 
セグメンテーションの実用を考えると、処理スピードと物体輪郭のエッジ部分が最優先である。
フレームレートは120FPSを目標にした。
また、セグメンテーションに使われているRecallとPrecisionの指標を参考し、評価を行った
（具体的な評価については、「6. 検証・評価」に記載）。

<!--- ここでは書かなくてもよいかも -->
<!-- 更に、応用環境への適応性のため、調整可能のパラメータを設定し、ユーザが自由に調整できるインターフェイスを用意した。-->

### 3.2 利用データ
DS5では、GS画像以外、モードによりfloodとspotのポイントクラウドまたはintensity画像が出力できる。（「2.1 DS5」に記載）
Upsamplingの入力としてはいくつか考えられるが、高FPSを満たすために今回は、GS画像をguideとして、floodポイントクラウドを入力とすることにした。

また、GSとspotポイントクラウドのUpsampling結果は補足の検証用に利用することとした。

理由は以下となる。
* ARタスクには、デプスマップの解像度に対して要求があり、Intensity画像の解像度では満足できない。Upsampling結果の解像度がguideに依存するので、解像度が大きいGS画像をguide画像として使用することになった。
* 近距離の前景と遠距離の背景のセグメンテーションがメインである。近距離のfloodモードがメインだと考えている。
* DS5では、floodとspotを両方出力すると、120FPSに至らない。すなわち、入力が120FPS未満となる。
* spotポイントクラウドは、遠い背景の情報が必要な場合、利用する。

### 3.3 Upsamplingのインターフェイス
UpsamplingモジュールはDS5の出力データの後段処理であり、DSY-01基板からのポイントクラウドを入力とし密なデプスマップを出力する。また、Upsampling処理がスパースなデプス信号の基に補間が行われるので、元信号からxy距離が離れるほど推定精度は低下する。そのため、Upsamplingの出力として、補間後の密なデプスマップと伴に、信頼度マップを出力する。信頼度は元信号との距離に応じ、0から1に変動する。詳細について、「4. アルゴリズムの検討」に記載。信頼度を利用して、更に綺麗なセグメンテーションが期待される。（信頼度の閾値によりフィルタリングの結果が図11に示す）

## 4. アルゴリズムの検討
### 4.1 前処理とメイン処理
機能の観点から、Upsamplingモジュールは前処理とメイン処理の２つ部分に分ける。それぞれのタスクは以下となる。
* メイン処理 : 疎な信号を高密度化する
<!--	* guide画像によりフィルタ算出
	* 入力とマスクに対するフィルタリング処理 --> <!--- いらない？ -->
	* フィルタリング処理
	* 信頼度計算
* 前処理 : 入力信号を成形しノイズを取り除く
	* 点群⇒デプスマップ
	* 視差ズレ対策
	* 誤測距対策

処理時間を短縮するため、実装の際前処理とメイン処理でが並列に実行できる部分は並列化している。詳細について、「5.1 処理流れ」に記載。

### 4.2 メイン処理の検討
まず、処理時間が最もかかる部分のUpsamplingメイン処理を検討した。ここで、信頼度計算を含まずフィルタの算出とフィルタリング処理のみを考慮している。

そのため、今まで開発した幾つかのUpsampling手法の精度とスピードの比較実験を行った。目的は２つがある：１つ目は、120 FPS（8.33 msec）の目標との距離を把握すること。２つ目は、最適切な手法を選ぶこと。


実験では、シミュレータで生成したCGデータを利用し、以下の４つのUpsampling手法を比較した。
データは、室内の3次元モジュールから50シーンの4つのFOVのRGB画像とデプスマップがある。スパース入力として、デプスマップからDS5とfloodモードと同じ密度で間引いて作成した。

<!--- 実験条件をもう少し追加してください。　使用したPC spec -->


* 比較手法
	* FBS (Fast Bilateral Solver)：ノイズに対する耐性ある手法である。入力はguideとスパースのデプスマップ以外、信頼度マップも必要となる。詳しく[Fast Bilateral Solver](https://arxiv.org/pdf/1511.03296.pdf)に記載
	* FGS (Fast Global Smoother)：スピードの早さが特徴である。
	* WFGS（Weighted FGS）：FGSをベースに、時間安定性を考慮する手法である。
	* PlanarFilter（Planar Filter）：FGSをベースに、平面性を維持する手法である。
評価結果は図4に示す。

実験よりFGSが最も早いことが分かった。$640 \times 480$の解像度の入力に対して、約5msecで、DS5の解像度（$960x540$）では約7msecになる。全体的な精度（MAE：Mean Absolute Error）には、PlanarFilterに近い良い結果だった。<!--- 次の文章いらない気がします -->また、どの手法でも、FOVが多ければ大きいほど、測距点の空間密度が低下するため精度が落ちた。

図4. Upsampling手法の比較
![700](imgs/compare_methods.png)

この実験の結果より、FGSを今回使用することに決めた。また、8.33 msecの目標に対しわずかの時間差があるので、他の処理にもなるべく軽くしないといけない状況である。

### 4.3 前処理の概説
DS5のから出力はレンズ歪補正とToFとGSセンサーのキャリブレーション済のものである。カメラパラメータにより、ポイントクラウドをデプスマップに変換し、Upsamplingに入力することができる。しかし、ToFとGSセンサーが同軸になっていないので、視差ずれによるオクルージョン領域により、背景の壁の領域が前景の手に重畳されてしまうような場所(以降視差ずれと呼ぶ)が発生する。また、エッジのところは前景と背景の光子が同じピクセルに返ってくるため測距点が不安定となり、誤る可能性が高くちらつきが発生する。
図5に示すように、視差ずれと誤測距ポイントの影響でUpsamplingの結果が劣化になる。

図5. 生信号でのUpsamplingの例（左：floodポイントとGS画像を位置合わせた画像、右：左のデータでのUpsampling結果。赤い枠内に視差ずれが発生し、紫の枠内に誤測距ポイントがある。誤る入力信号により、結果には綺麗なエッジにならない。）
![](imgs/raw_signal.png)

そこで、今回は視差ずれのポイントと誤測距点をそれぞれ除去する改善案を提案する。具体的に、ポイントの位置関係により、視差ずれのポイントを検出し、削除する。そして、デプスマップのエッジ部分から、guide画像の情報を参照し、誤る可能のところを削除する。以下に、処理の詳細を説明する。

#### 4.3.1 視差ずれの削除
まず、視差ずれによるデプスマップ上の特徴から、ずれのポイントの削除を行う。図に示した通り、DS5のdToFセンサはRGBセンサの右にあるので、視差ずれのところに観測ポイントが左にシフトする。
図.5の左図のように、観測ポイントの間隔が殆ど同じであるが、視差ずれの場所（赤い枠内をご参照ください）のポイントが重なってある。この特徴を基づいて、以下の方法でずれポイントを判断する。
1. floodのポイントを行ごとに左から右へ走査する。各ポイント（対象）がその左のポイントを参照し、視差ずれかどうかの判断を行う。
2. まず、対象をデプスマップの座標($x,y$)に変換し、左のポイントの$x$座標と比較する。もし左のポイントより左になるまたは左のポイントとの距離が閾値より小さい場合、候補１とする。
3. 次に、左のポイントのデプス差と対象デプスの割合を閾値より大きい場合、候補２とする。（誤判断を抑えるための条件）
4. 候補１と候補２に両方になるポイントがずれポイントとする。

図6. 検出された視差ズレポイントの例（黄色枠）。右は視差ズレの測距点、左は正しい測距点
![100](imgs/depth_filtering_method.png)


#### 4.3.2 誤測距ポイントの削除 
次には、誤測距ポイントの削除について述べる。図.5の紫枠のように、GS画像から見ると、白っぽい背景と黒っぽい指がある。そして、dToFセンサにより、青色とオレンジ色のポイントが観測された。本来、指から青色の測距ポイントになり、背景からオレンジ色の測距ポイントになるはずである。しかし、エッジ部分の測距ポイント安定性が低いため、図のように白い背景から青色測距ポイントが出る誤測距の可能性がある。そこで、我々が誤測距ポイント検出する方法を提案した。そして、誤測距ポイントの削除により、より綺麗なUpsampling結果が得られる。

誤測距ポイントの原因として、エッジ部分からの反射が不安定と見られる。そのため、エッジ周辺領域を注目し、誤測距ポイントの検出を考えている。ここで、我々がデプスのエッジを利用する。その原因は2つがある。1つは、GS画像のエッジが照明変化や動きなどからの影響を受けやすいため、安定性が低い。もう１つは、スパースのデプスマップの解像度（$80 \times 60$）はGS画像（$960 \times 540$）より遥かに小さいので、早い処理ができる。抽出方法は、対象ポイントの周りの8ポイントから４方向（上下左右と斜めの２方向）の勾配を計算し、閾値（$0.1m$に設定）を超えるとエッジポイントとする。検出結果について、図7に示すように、スパースのデプスマップ（左図）から、エッジ（右図）が抽出できた。

図7. デプスエッジの例（左はスパースのデプスマップ、右は抽出したエッジ）
![](imgs/depth_edge.png)

更に、GS画像の情報を利用し、以下の手順で誤測距ポイントを判断する。

1. 抽出したエッジポイントから１つポイントを対象ポイントとする。
2. 対象ポイントと周りの測距ポイント（8点か24点）と比較する。差分が閾値（実験では0.1に固定）より大きい場合１に、そもなければ０にするように、特徴ベクトル（$\bold{f1}$）を作る。
3. 対象ポイントと周りの測距ポイントに対応するGS画像のピクセル値を比較する。差分が閾値（実験では45に固定）より大きい場合１に、そもなければ０にするように、特徴ベクトル（$\bold{f2}$）を作る。
4. ２つの特徴ベクトル（$\bold{f1,f2}$）のハミング距離が閾値（）を超えると誤測距ポイントと判断する
5. 手順１に戻って、全てのエッジポイントを走査する。

図8のように、エッジ部分から誤測距ポイント（中空の円で表示）が検出される。この手法周りのポイントが全て正しいと前提にする。実際は、誤測距ポイントが隣接する可能性があるので、我々が同じ処理を２回行う。１回目では、著し誤るポイントを洗い出する。２回目では、一回目で判断した誤測距ポイントを無視し、判断を行う。最終結果について、実験の部分（図12）に記載。

図8. 誤測距ポイント（中空の円で表示）検出の例
![](imgs/filter1.png)


### 4.3 信頼度
[[#2 関連技術]]に説明したFGSのアルゴリズムでは、補間後のデプスマップだけ出力される。
しかし、精度に求めるユーザに対して、信頼度情報も必要である。
そのため、Upsampling出力のデプスマップの各ピクセルの信頼度を計算し、信頼度マップを提供することになる。
基本的に、入力のスパースポイント（直接に観測されたポイント）の精度が最も高く、信頼度が高い。
補間結果は入力との距離により、遠ければ遠いほど精度が悪くなり、また色が異なるところへ引き延ばしたいるところほど信頼度が低く設定する。単純に、各ピクセルと入力ポイントの距離算出に時間かかるため、信頼度としてUpsamplingの中間結果を活用した。
具体的には、マスクのフィルタリング結果(式(3)の分母$H$、$H = ((I+\lambda A)^{-1}h(m)$)を利用する。式の詳細について、「2.3 デプスUpsampling」に記載。
また上式では、設定したパラメータ$\lambda$によって変動があるため、結果に$\lambda$を掛け、正規化する
最後、扱いやすいため、信頼度の範囲を0~1に設定した。図14に信頼度マップの例を示している。
ユーザが信頼度閾値(0~1)に設定し、信頼度の高いUpsampling結果のみ使うことができる。
実験では、信頼度閾値を$0.1$に固定した。


## 5. 実装とパラメータ
### 5.1 処理流れ
前の説明のようにUpsamplingが前処理とメイン処理を分ける。
処理スピードのため、処理1、２、３が並列になっている。
具体的な流れは以下となる。ポイントクラウドの処理とRGB画像の処理に情報交換がない部分を並列化する。
```mermaid
graph TB
P2(2.エッジ抽出)
P1(1.視差ずれ削除)
P3(3.FGS用フィルタの算出)
P4(4.誤測距ポイント削除)
P5(6.FGSフィルタリング処理)
P6(5.デプスマップへの変換)

I1[入力GS画像]
I2[入力ポイントクラウド]
I3[視差なしのポイントクラウド]
I4[エッジ領域]
I5[FGS用フィルタ]
I6[誤測距なしのポイントクラウド]
I7[デプスマップ]
R1[密なデプスマップ]
R2[信頼度マップ]
I2 --> P1　--> I3
I3 --> P2 --> I4
I4 --> P4 --> I6
I1 --> P4
I1 --> P3 --> I5
I6 --> P6 --> I7
I7 --> P5 --> R1
I5 --> P5
P5 --> R2
```

### 5.2 パラメータ調整
パラメータにより、Upsamplingの性能（スピード・精度）が変わることがある。本開発では、
具体的な使用シーンによるパラメータチューニングを行っていない。
パラメータを変更するAPIをユーザに提供する。
調整可能のパラメータを以下の表に示す。
* 前処理パラメータ

| パラメータ             | タイプ | 範囲  | 説明             |
| ----- | ---- | ----- | ------- |
| z_continuous_thresh    | float  | 0~1   | デプス上近隣判断閾値。小さければ小さいほど、消す点数が多い。 |
| occlusion_thresh       | float  | 0~20  | 視差ズレ判断閾値。大きければ大きいほど、消す点数が多い。     |
| depth_diff_thresh | float    | 0.0~1.0  | デプス上異なるところと判断する基準である。単位はメートル。閾値以上の差があれば、異ると判断される  |
| guide_diff_thresh  | float | 0~255 | GS画像上異るところと判断する基準である。単位は画素値。閾値以上の差があれば、異ると判断される |
| min_diff_count  | int    | 0~24 | 対象ポイントの周りポイントが異る（GSとデプス画像上の傾向）最小数。それ以上になると、対象ポイントを誤測距ポイントと判断される  |
| range_flood            | int    | 2~40  | floodに対するUpsamplingの範囲、処理スピードに影響なし        |
  
* メイン処理パラメータ

| パラメータ | タイプ |  範囲   |  説明 |
|:---- |:--- |:---:|:---:|
| fgs_lambda_flood       | float  | 0.1~100 |  空間分解能 |
| fgs_sigma_color_flood  | float  |  1~20   |  色空間分解能 |
| fgs_lambda_attenuation | float  |  0.25   |  固定値 |
| fgs_lambda_spot        | float  | 1~1000  |  固定値 |
| fgs_sigma_color_spot   | float  |  1~20   |  固定値 |
| fgs_num_iter_flood     | int    |   1~5   | iteration回数、大きければ大きいほど、スピードが遅くなる |
| fgs_num_iter_spot      | int    |   1~5   |  固定値 |
  
  
## 6. 検証・評価<span id='s6'></span>
次に、前処理の有効性を検証するため、DS5で撮影した画像から手のセグメンテーションの実験を行った。
### 6.1 実験条件
撮影は図9に示す環境で行った。手がセンサと約$20$cmのところにゆっくり拭き、背景（壁）がセンサと$70$cmである。撮った数フレームのうち、１フレームを評価対象とした。
パラメータはヒューリスティックにデフォルト値を設定した。
提案手法の有効性を検証するため、前処理なし(original)と視差ずれ削除処理のみ(pd)での実験も行った。
評価用PCのスペックは以下となる。GPUを利用していない。
* CPU： AMD 3700x 3.6GHz
* RAM： 64 GB (2666 MHz)
### 6.2 評価基準
Ground Truth（GT）として、図9のように人工でラベリングした手の領域を用意した。

図9. 評価用画像と手領域のラベリング
![450](imgs/eva_boarder.png)

セグメンテーションには、デプスの閾値（$T$）により手と背景を区別する。
実環境に手よりセンサと近い部分（例えば、センサが置いてある机）が取られる可能性がある。評価への影響を防ぐため、図10のようにラベリング領域の外接四角形を数ピクスセル大きくした領域（青い領域）を注目領域とした。評価には注目領域以外の部分を無視するようになった。
評価基準が図10に示す。ある閾値での結果（緑の円形）に対して、GTと重なる部分がTP、背景と重なる部分がFPとなる。また、背景と判断された部分に対して、GTによりFNとTNを分ける。

図10. 評価基準
![500](imgs/eva_gt.png)

そして、下式でPrecisionとRecallを算出する
$$
\mathtt{Precision} = \frac{\mathtt{TP}}{FP+TP}
$$
$$
\mathtt{Recall} = \frac{\mathtt{TP}}{TP + FN}
$$

### 6.3 実験結果
$T$の変化に応じる結果のRecall-Precision図を図.11に示す。$T$が大きければ大きいほど、得られる手領域が増え、Recallが大きくなる。一方、Precisionが低くなる。
Recallの高い（$95\%$以上）部分を注目し、提案した前処理では前処理なしより高いPrecisionが得られた。


図11. $T$の変化による結果。original:前処理なし、pd:視差ずれ削除のみ、pd+ec:提案の前処理（視差ずれと誤測距ポイントの削除）
![600](imgs/eva_results.png)

図12にUpsamplingの入力と結果（同じ閾値での信頼度によるフィルタリング処理あり）を示している。
現信号の結果と比べ、提案した視差ずれ削除と誤測距ポイント削除処理によりエッジ部分の精度改善が分かった。
図13と図14は評価シーンのUpsampling処理後のポイントクラウドと信頼度マップである。
処理スピードはパラメータにより変わるが、80～140FPSの範囲内に変化する。

図12. Uspamplingの結果の例（上：前処理なし。中：視差ずれ削除のみ。下：視差ずれ削除＋誤測距ポイント削除。左：GS画像＋測距ポイント、右：信頼度＞0.1Upsampling結果1）
![](imgs/original_dmp.png)
![](imgs/pd_dmp.png)
![](imgs/pd+ec_dmp.png)

図13. Upsampling後のポイントクラウド（緑矢印がデバイスの向き方向）
![350](imgs/3d_pointCloud.png)

図14. 出力の信頼度マッ（黒いところが低い、白いところが高い）
![500](imgs/confidence_map.png)

### 6.4 考察
実験を通して、視差ずれと誤測距の問題とそれよりエッジ部分のUpsampling結果への悪い結果が確認できた。
また、提案した前処理での改善効果を検証した。
処理スピードについて、要求の120FPSをクリアした。
精度について、パラメータチューニングよりもっと良い結果が得られるが、
使用の経験値ではベストパフォーマンスに近いと考えている。
結果として、Recall=95%の場合、Precisionが90%弱になる。
期待されるRecallとPrecisionが共に95%にすこし距離がある。
精度へ影響を与える要因が以下と考える。
* **欠損** 視差ずれ削除とご測距ポイント削除処理により、エッジ部分のポイントが多く消された。それにより、Upsamplingで復元できない可能性がある。図12の結果のように、エッジ部分には欠損が出た。背景の欠損部分は結果に影響を与えないが、前景の欠損はRecall低下の原因になる。
* **Guide画像の画質** Upsamplingの結果がGuide画像と緊密な関係がある。照明条件や動きによるボケなどの影響で、GS画像のGuide機能が弱める。
* **苦手シーン** 図15のような極端なケースである。手（薬指と小指）と机の色が区別しにくいので、誤測距ポイントの判断が不可能である。更に、黒い机から測距ポイントがないため、Upsamplingの際、手からの測距ポイントが遠く伸ばしてしまい、指部分の結果が膨らんできた。ちなみに、DS5の最大測距距離を超える場合あるいは反射しにくいところ（例えば、黒いところと斜め反射のところ）から測距ポイントが出ない。例のように、Guide画像の色分けが効かない上、測距ポイントが十分ではないシーンは苦手シーンとなる。

これらの問題に対して、以下の対策が考えれる。但し、処理スピードなどを配慮するので、本開発には深く検討していない。
* **欠損** 欠損領域は、エッジ部分が多く、信頼度低いところである（信頼度マップ（図14）とポイントクライド図（図13）をご参照ください）。信頼度マップに基づいて、エッジ情報を保たすフィルタリング処理を追加すれば、改善できると考える。
* **Guide画像の画質** ソフトウェアでの画質改善処理以外、GSセンサの改善が期待される。例えば、RGBセンサに変更する。
* **苦手シーン** 安定的な測距ポイントがあれば、改善できると考える。例えば、spotモードで得た測距ポイントを使用する。

図15. 苦手シーン
![500](imgs/bad_example.png)

## 7. まとめ
本開発には、AR応用に一つの重要なタスクのセグメンテーションに対して、DS5のUpsamplingアルゴリズム開発を行った。
ユーザ要求とセンサ特性の分析の上、前処理ありのフィルタベースUpsampling手法を開発した。
* 達成点
	* スピード要求を満たすことができた。
	* 視差ずれと誤測距ポイント：軽い処理である程度に抑えた。
* 問題点
	* パラメータの調整：シーンによる最適の設定が変わる。
	* 精度について、期待との距離がある。要因と対策が6.4考察に述べた。


今後は、Upsamplingの精度に注力すると考える。
まず、苦手シーンの対策である。センサの改善以外、ソフトウェアでの改善方法がある。今回、処理スピードを配慮し実行していない処理を試す。更に、学習ベースのUpsampling手法を検討する。
その他、DS5の出力SpotとIntensity情報を利用する。Spotモードの測距ポイントがスパースが、測距距離が長い。
Intensity画像の解像度が低いが、視差ずれがないというメリットがある。
これらのメリットを利用することが期待される。